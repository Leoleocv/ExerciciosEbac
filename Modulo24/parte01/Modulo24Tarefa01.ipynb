{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 diferenças entre Random Forest e AdaBoost:\n",
    "\n",
    "- Método de ensemble: Random Forest usa bagging (bootstrap aggregating), criando árvores independentes em paralelo com amostras aleatórias dos dados. AdaBoost usa boosting, construindo árvores sequencialmente onde cada nova árvore foca nos erros das anteriores.\n",
    "\n",
    "- Ponderação de amostras: Random Forest trata todas as amostras com igual importância durante o treinamento. AdaBoost atribui pesos maiores às amostras classificadas incorretamente, forçando o modelo a focar nos exemplos difíceis.\n",
    "\n",
    "- Complexidade das árvores: Random Forest geralmente usa árvores profundas e completas. AdaBoost usa \"árvores fracas\" (weak learners), frequentemente árvores de decisão com apenas um nível (stumps) ou poucos níveis.\n",
    "\n",
    "- Sensibilidade a outliers e ruído: Random Forest é mais robusto a outliers e ruído nos dados. AdaBoost é mais sensível a outliers, pois aumenta progressivamente o peso das amostras mal classificadas.\n",
    "\n",
    "- Mecanismo de votação: Random Forest utiliza votação com peso igual para todas as árvores na previsão final. AdaBoost implementa uma votação ponderada, na qual árvores com melhor desempenho recebem maior influência na decisão final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemplo do AdaBoost:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9533333333333334\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "base_estimator = DecisionTreeClassifier(max_depth=1)\n",
    "ada_clf = AdaBoostClassifier(estimator=base_estimator, algorithm='SAMME', random_state=42)\n",
    "\n",
    "scores = cross_val_score(ada_clf, X, y, cv=5)\n",
    "print(scores.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Principais Hyperparametros do AdaBoost\n",
    "\n",
    "- n_estimators: Define o número máximo de estimadores (classificadores fracos) que serão usados na construção do modelo. Um número maior pode melhorar o desempenho até certo ponto, mas aumenta o tempo de processamento e pode levar a overfitting.\n",
    "\n",
    "- learning_rate: Também conhecido como \"shrinkage\", controla a contribuição de cada classificador fraco no ensemble final. Valores menores (como 0.01 ou 0.1) geralmente requerem mais estimadores mas podem oferecer melhor generalização.\n",
    "\n",
    "- algorithm: Determina o algoritmo de boosting usado. No scikit-learn, as opções são 'SAMME' e 'SAMME.R' (embora SAMME.R esteja sendo depreciado). SAMME é o algoritmo AdaBoost original para classificação multiclasse, enquanto SAMME.R usa probabilidades de classe.\n",
    "\n",
    "- base_estimator: Define o tipo de classificador fraco utilizado. Embora o padrão seja uma árvore de decisão com profundidade = 1 (decision stump), outros classificadores podem ser escolhidos.\n",
    "\n",
    "- base_estimator__max_depth: Quando se usa árvores de decisão como estimadores base, a profundidade máxima de cada árvore é crucial. Árvores mais profundas capturam relações mais complexas, mas são mais propensas a overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizando GridSearch para encontrar os melhores hyperparametros para o conjunto de dados do exemplo (load_iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "{'estimator__max_depth': 2, 'learning_rate': 0.1, 'n_estimators': 30}\n",
      "0.9428571428571428\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'estimator__max_depth': [1, 2, 3],\n",
    "    'n_estimators': [30, 50, 70],\n",
    "    'learning_rate': [0.01, 0.1, 1.0],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    ada_clf,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "print(grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "melhor_model = grid_search.best_estimator_\n",
    "\n",
    "y_pred = melhor_model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
